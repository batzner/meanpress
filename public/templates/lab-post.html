<p>I let a neural network read long texts one letter at a time. Its task was to predict the next letter based on those it had seen so far. Over time, it recognized patterns between letters. Find out, what it learned, by feeding it some letters below. When you click the send button on the right, it will read your text and auto-complete it.</p>
<p>You can choose between networks that read a lot of Wikipedia or US Congress transcripts etc.</p>

<div id="talk-box">
    <table>
        <tr id="talk-box-heading">
            <td></td>
            <td class="no-stretch">
                <div>Generate text from</div>
                <div class="btn-group" role="group" aria-label="Dataset choice">
                    <button type="button" value="wiki" onclick="selectDataset(this.value)" class="btn btn-default dark">Wikipedia</button>
                    <button type="button" value="congress" onclick="selectDataset(this.value)" class="btn btn-default dark">US Congress</button>
                    <button type="button" value="sherlock" onclick="selectDataset(this.value)" class="btn btn-default dark">Sherlock Holmes</button>
                    <button type="button" value="southPark" onclick="selectDataset(this.value)" class="btn btn-default dark">South Park</button>
                    <button type="button" value="goethe" onclick="selectDataset(this.value)" class="btn btn-default dark">Goethe</button>
                </div>
            </td>
            <td></td>
        </tr>
        <tr id="talk-box-body">
            <td></td>
            <td>
                <div id="talk-box-input" onclick="focusOnInput()">
                    <div id="text-input" contentEditable="true" oninput="onInput()"></div>
                    <div id="text-input-output-bridge">...</div>
                    <span id="text-output"></span>
                </div>
            </td>
            <td>
                <button id="send-button" type="button" class="btn btn-default round btn-icon" onclick="completeText()">
                    <span class="fa fa-paper-plane"></span>
                </button>
            </td>
        </tr>
    </table>
</div>

<p>Here is the detailed description of what I did and what this post is about: I used a specific form of recurrent neural networks, the <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM (Long Short-Term Memory)</a>, to generate a language model for a given text corpus. Because I fed it one letter at a time, it generated a character-level language model. For implementation, I used <a href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<p>Now, why do I write a blog post about that?</p>

<ul>
    <li>The idea is not new at all. I was inspired by <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">this popular blog post</a> by Andrej Karpathy. If you would like to know more about the theory behind this post, this is an excellent resource. He also trained his network on character-level on Shakespeare, Wikipedia, Linux Source Code etc. The results are quite funny.</li>
    <li>I implemented the LSTM from scratch with TensorFlow. You can check out the <a href="https://github.com/batzner/tensorflow-pet-projects">GitHub repository</a>. However, since it was my first TensorFlow project, I don't think the code is noteworthy. For implementing character-level language models with LSTMs in Tensorflow, <a href="https://github.com/sherjilozair/char-rnn-tensorflow">this repo</a> and <a href="https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py">this TensorFlow example</a> might be better points to start. Nevertheless, my code proves that five TensorFlow models with about 10 million parameters each can run simultaneously on a single <a href="https://aws.amazon.com/ec2/instance-types/#instance-type-matrix">AWS t2.micro</a> instance with only 1 GiB of RAM.</li>
    <li>What <strong>is</strong> new about this post is that, firstly, it contains an interactive text box where you can find the strengths and weaknesses of the trained models and, secondly, I am publishing my complete hyperparameter odyssey. Below, I will explain, how I found the hyperparameters (batch size, learning rate, number of layers etc.) for the final networks - what mistakes I made and what I learned from them. So if hyperparameter-tuning of neural networks is a bit of a mystery to you, this post might save you some time and money spent on the inefficient training of your models.</li>
</ul>

<p>I will also explain why the networks from the box above behave like they do. For example, why the US Congress net performs quite well while the Wikipedia net always changes the subject of the sentence to the United States.</p>

<p><a href="https://github.com/batzner/tensorflow-pet-projects">Code to this post</a></p>

<h3>Setup</h3>
<h5>Dataset</h5>
<p>I chose a small dataset hoping that my findings would transfer to large datasets as well. The dataset consists of the whole Sherlock Holmes corpus by Sir Arthur Conan Doyle. It is a <a href="https://sherlock-holm.es/stories/plain-text/cano.txt">.txt file</a> (3.6 MB) containing roughly 3.6 million characters and 650 thousand words after preprocessing. The only preprocessing I did was to remove indentation. I kept all line breaks even if their only purpose was formatting. I split the dataset into 90% training and 10% validation.</p>
<h5>Model</h5>
<p>To feed the text to the model, I one-hot encoded each character to a vector. The corpus contains 97 different characters causing input vectors of length 97. In the net, a softmax layer follows the LSTM layers and serves as a output layer. Its 97 neurons are fully connected to the last LSTM layer. The softmax layer outputs a 97-dimensional vector containing the predicted probability for each character being the next one.</p>
<p>For optimization, I used <a href="http://sebastianruder.com/optimizing-gradient-descent/index.html#rmsprop">RMSprop</a>. It is an enhancement of the classic Stochastic Gradient Descent with the improvement that it uses a different learning rate for every single parameter. This learning rate depends on the last gradients of that parameter. Parameters that recently had multiple large updates get a smaller learning rate to avoid oscillation around minima of the loss function. That brings us to our loss function:</p>
<h5>Perplexity - the WTF metric</h5>
<p>As a loss function I chose the cross-entropy loss based on the prediction the model made at each step / for each character. However, in the charts below I exponentiated each loss value with base 2. This makes the values easier to interpret, because: the cross-entropy \(H\) can be interpreted as the average number of bits that the model would need to encode the next letter at each step.
    <button class="show-more" data-target-id="perplexity-explanation" data-show-text="Why?" data-hide-text="OK, got it.">Why?</button>
</p>
<div id="perplexity-explanation" class="detail">
    <p>Say the model's task is to encode the text to bits and its aim is to minimize the number of bits it needs. For example, it might have recognized some likely characters, so it gives them a low number of bits. It encodes A to 01 and X to 00101. That is smart because A occurs way more often than X, so why spend an equal amount of bits on X as on A? So the better the model is at predicting the next character the less bits it will need to encode the text. This makes the cross-entropy a good error measure / loss function to optimize. See <a href="http://stats.stackexchange.com/questions/80967/qualitively-what-is-cross-entropy">this excellent answer on StackOverflow</a> for more info.</p>
    <p>Because our model learns patterns between characters in sentences it would not just look at the probability of each letter based on the number of occurrences in the text. Instead, it is smarter and uses the current position in the text for encoding and decoding. For example, if the whole text is a repetition of the pattern ABCDABCD, it wouldn't have to give each letter 2 bits based on its direct probability of 0.25. Instead, it would just have to encode the first letter, the rest of the text would be directly determined by that. So, it needs 2 bits <strong>for the whole text.</strong></p>
    <p>Anyhow, why exponentiate the cross-entropy? So remember that the cross-entropy \(H\) gives us the average number of bits the model would need to encode the next letter at each step.</p>
</div>
<p>Thus, \(2^{H}\) gives us the average number of possibilities it has to choose from. Say our input data consists of 1000 characters and the model achieves a cross-entropy of 3.322 bits per character. This would mean a perplexity of \(2^{3.322} = 10\). So, the model is as confused on the input data as if it had to choose uniformly and independently among 10 possibilities for each character (example taken from <a href="https://en.wikipedia.org/wiki/Perplexity">this Wiki article</a>).</p>
<h5>Initial Hyperparameters</h5>
<ul>
    <li>Number of LSTM layers: 2</li>
    <li>Number of neurons per layer: 512</li>
    <li>Batch size: 1</li>
    <li></li>
</ul>
<p>Small details:</p>
<li>
    <ul>I <a href="http://www.wildml.com/deep-learning-glossary/#gradient-clipping">clipped the gradients</a> to an L2 norm of 5.</ul>
</li>

<p>Using RMSprop as an optimizer, which is still SGD, but with an improvement: it uses a different learning rate for each parameter, which depends on the last gradients of that parameter. Thus, parameters that recently had multiple large updates get a smaller learning rate.
    http://sebastianruder.com/optimizing-gradient-descent/index.html

    Dataset: Sherlock Holmes
    Write exact metrics for every dataset, number of words, chars, bytes etc.

    4 mio chars as validation set???</p>

<h3>1. Batch Size:</h3>
<div class="col-xs-9 no-padding">
    <canvas id="batch-size-decay-chart" class="chart" width="600" height="300"></canvas>
</div>
<div class="col-xs-3 no-padding">
    <canvas id="batch-size-epoch-duration-chart" width="200" height="300"></canvas>
</div>

<p>generally unfair to compare the batch sizes with the same learning rate. Because the steps, which the optimizer takes with larger batch sizes, are more stable, it can use a higher learning rate. Thus, each batch_size has a different optimal learning rate. This is to some extent compensated by the RMSProp optimizer, which adapts the learning rate over time.

    1/10/20 definitely too inefficient
    1/10 overfit faster, because they only see a small portion of the text at every step so they lose the sense for the whole text???
    500/2000 seem to get stuck in low local minima, because their minima donâ€™t change as fast as with small batch_sizes

    Why can't we just scale the batch size to whatever fits in the memory?
    Good answer: https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent/answer/Brian-Wong-21
    While the gradient of a single data point is a lot noisier than the gradient of a 100-batch, the gradient of a 100-batch is not that much noisier than that of a 100,000-batch. So the additional 99,900 samples in that batch are useless, because we can use the almost the same step size with the 100-batch.
    Also, noisiness prevent getting stuck in low local minima, because the error function and therefore the minima change for every batch.

    "But noisiness isn't all bad. In particular, suppose that our error function is particularly pernicious and has a bunch of little valleys. If we used the entire training set to compute each gradient, our model would get stuck in the first valley it fell into (since it would register a gradient of 0 at this point). If we use smaller mini-batches, on the other hand, we'll get more noise in our estimate of the gradient. This noise might be enough to push us out of some of the shallow valleys in the error function.

    There is thus an important trade-off to consider between being able to jump out of shallow minima and making sure that you eventually converge to some minimum instead of bouncing around.

    In practice, small to moderate mini-batches (10-500) are generally used, combined with a decaying learning rate, which guarantees long run convergence while maintaining the power to jump out of shallow minima that are encountered early on."

    -> Choose 200 as batch size for future experiments, because it has a similar time per epoch, but it converges faster.
    Also, think about batch training a language model on a text
    Graphic on splitting up the text into batches

    How does batch processing work for character-level language model generation? How can we split up the dataset without destroying the logical dependencies between characters? You just start each batch at equidistant points in the dataset, so that the chars within a batch are never split up. See ptb_iterator(...) here for an implementation.
    Lower batch size prevents splitting up the text into too many small parts and therefore destroying the logical connections between those parts.

    LESSON LEARNED: Choose a good batch size first, because it affects the training time of future experiments. Also, the optimal value for the learning rate depends on the batch size.

    Autocomplete of the 200 batch net: "The house which had been the strange problem which had been the strange of the man who had been the strange of the man who had been the strange of the man who had been the strange of the man who had been the strange of the man who had been the stran"</p>


<h3>All Experiments</h3>
<div class="col-xs-9">
    <canvas id="flexible-chart" class="chart" data-width="600" data-height="300"></canvas>
</div>
<div class="col-xs-3">
    <div class="chart-form-group">
        <div>
            <label for="run-group-select">Experiment</label>
            <div class="btn-group dropdown-full-width">
                <button id="run-group-select" type="button" value="batch_size" class="btn btn-default dropdown-toggle" onchange="plot()" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    <span class="choice">Batch Size</span> <span class="caret"></span>
                </button>
                <ul class="dropdown-menu">
                    <li><a href="#" data-value="batch_size">Batch Size</a></li>
                    <li><a href="#" data-value="learning_rate_512">Learning Rate</a></li>
                    <li><a href="#" data-value="learning_rate_decay">Learning Rate Decay</a></li>
                    <li><a href="#" data-value="num_timesteps">Number of Timesteps</a></li>
                    <li><a href="#" data-value="num_neurons_1024_failed_starts">1024 Neurons Failed Starts</a></li>
                    <li><a href="#" data-value="learning_rate_1024">Learning Rate (1024 Neurons)</a></li>
                    <li><a href="#" data-value="num_neurons">Neurons per Layer</a></li>
                    <li><a href="#" data-value="output_keep_prob">Output Keep Prob.</a></li>
                    <li><a href="#" data-value="num_layers">Number of Layers</a></li>
                    <li><a href="#" data-value="reset_state_interval_tokens">Reset State after Tokens</a></li>
                    <li role="separator" class="divider"></li>
                    <li><a href="#" data-value="wiki">Wikipedia</a></li>
                    <li><a href="#" data-value="south_park">South Park</a></li>
                    <li><a href="#" data-value="congress">Congress Transcripts</a></li>
                    <li><a href="#" data-value="goethe">Goethe Poems</a></li>
                </ul>
            </div>
        </div>
        <div>
            <label>X Axis</label>
            <div class="btn-group dropdown-full-width">
                <button id="x-axis-select" type="button" value="minutesSinceStart" class="btn btn-default dropdown-toggle" onchange="plot()" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    <span class="choice">Training Time</span> <span class="caret"></span>
                </button>
                <ul class="dropdown-menu">
                    <li><a href="#" data-value="minutesSinceStart">Training Time</a></li>
                    <li><a href="#" data-value="epochs">Epochs</a></li>
                </ul>
            </div>
        </div>
        <div>
            <label for="y-axis-select">Y Axis</label>
            <div class="btn-group dropdown-full-width">
                <button id="y-axis-select" type="button" value="lossesValid" class="btn btn-default dropdown-toggle" onchange="plot()" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    <span class="choice">Validation Loss</span> <span class="caret"></span>
                </button>
                <ul class="dropdown-menu">
                    <li><a href="#" data-value="lossesValid">Validation Loss</a></li>
                    <li><a href="#" data-value="lossesTrain">Training Loss</a></li>
                </ul>
            </div>
        </div>
        <div>
            <label for="y-axis-range">Y Axis Range</label>
            <input id="y-axis-range">
        </div>
        <div>
            <button id="export-button" type="button" class="btn btn-default" onclick="exportChart()">Export Chart</button>
        </div>
    </div>
</div>

<input id="stylesheets-input" value="stylesheets/posts/char-lm.css" style="display: none;">
<input id="javascripts-input" value="https://cdnjs.cloudflare.com/ajax/libs/he/1.1.1/he.min.js javascripts/posts/char-lm/text-complete.js javascripts/posts/char-lm/plot-flexible.js javascripts/posts/char-lm/plot.js" style="display: none;">