<p>I let a neural network read long texts one letter at a time. Its task was to predict the next letter based on those it had seen so far. Over time, it recognized patterns between letters. Find out, what it learned, by feeding it some letters below. When you click the send button on the right, it will read your text and auto-complete it.</p>
<p>You can choose between networks that read a lot of Wikipedia or US Congress transcripts etc.</p>

<div id="talk-box">
    <table>
        <tr id="talk-box-heading">
            <td></td>
            <td class="no-stretch">
                <div>Generate text from</div>
                <div class="btn-group" role="group" aria-label="Dataset choice">
                    <button type="button" value="wiki" onclick="selectDataset(this.value)" class="btn btn-default dark">Wikipedia</button>
                    <button type="button" value="congress" onclick="selectDataset(this.value)" class="btn btn-default dark">US Congress</button>
                    <button type="button" value="sherlock" onclick="selectDataset(this.value)" class="btn btn-default dark">Sherlock Holmes</button>
                    <button type="button" value="southPark" onclick="selectDataset(this.value)" class="btn btn-default dark">South Park</button>
                    <button type="button" value="goethe" onclick="selectDataset(this.value)" class="btn btn-default dark">Goethe</button>
                </div>
            </td>
            <td></td>
        </tr>
        <tr id="talk-box-body">
            <td></td>
            <td>
                <div id="talk-box-input" onclick="focusOnInput()">
                    <div id="text-input" contentEditable="true" oninput="onInput()"></div>
                    <div id="text-input-output-bridge">...</div>
                    <span id="text-output"></span>
                </div>
            </td>
            <td>
                <button id="send-button" type="button" class="btn btn-default round btn-icon" onclick="completeText()">
                    <span class="fa fa-paper-plane"></span>
                </button>
            </td>
        </tr>
    </table>
</div>

<p>Here is the detailed description of what I did and what this post is about: I used a specific form of recurrent neural networks, the <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM (Long Short-Term Memory)</a>, to generate a language model for a given text corpus. Because I fed it one letter at a time, it generated a character-level language model. For implementation, I used <a href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<p>Now, why do I write a blog post about that?</p>

<ul>
    <li>The idea is not new at all. I was inspired by <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">this popular blog post</a> by Andrej Karpathy. If you would like to know more about the theory behind this post, this is an excellent resource. He also trained his network on character-level on Shakespeare, Wikipedia, Linux Source Code etc. The results are quite funny.</li>
    <li>I implemented the LSTM from scratch with TensorFlow. You can check out the <a href="https://github.com/batzner/tensorflow-pet-projects">GitHub repository</a>. However, since it was my first TensorFlow project, I don't think the code is noteworthy. For implementing character-level language models with LSTMs in Tensorflow, <a href="https://github.com/sherjilozair/char-rnn-tensorflow">this repo</a> and <a href="https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py">this TensorFlow example</a> might be better points to start. Nevertheless, my code proves that five TensorFlow models with about 10 million parameters each can run simultaneously on a single <a href="https://aws.amazon.com/ec2/instance-types/#instance-type-matrix">AWS t2.micro</a> instance with only 1 GiB of RAM.</li>
    <li>What <strong>is</strong> new about this post is that, firstly, it contains an interactive text box where you can find the strengths and weaknesses of the trained models and, secondly, I am publishing my complete hyperparameter odyssey. Below, I will explain, how I found the hyperparameters (batch size, learning rate, number of layers etc.) for the final networks - what mistakes I made and what I learned from them. So if hyperparameter-tuning of neural networks is a bit of a mystery to you, this post might save you some time and money spent on the inefficient training of your models.</li>
</ul>

<p>I will also explain why the networks from the box above behave like they do. For example, why the US Congress net performs quite well while the Wikipedia net always changes the subject of the sentence to the United States.</p>

<p><a href="https://github.com/batzner/tensorflow-pet-projects">Code to this post</a></p>

<h3>Setup</h3>
<h5>Dataset</h5>
<p>I chose a small dataset hoping that my findings would transfer to large datasets as well. The dataset consists of the whole Sherlock Holmes corpus by Sir Arthur Conan Doyle. It is a <a href="https://sherlock-holm.es/stories/plain-text/cano.txt">.txt file</a> (3.6 MB) containing roughly 3.6 million characters and 650 thousand words after preprocessing. The only preprocessing I did was to remove indentation. I kept all line breaks even if their only purpose was formatting. I split the dataset into 90% training and 10% validation.</p>
<h5>Model</h5>
<p>To feed the text to the model, I one-hot encoded each character to a vector. The corpus contains 97 different characters causing input vectors of length 97. In the net, a softmax layer follows the LSTM layers and serves as a output layer. Its 97 neurons are fully connected to the last LSTM layer. The softmax layer outputs a 97-dimensional vector containing the predicted probability for each character being the next one.</p>
<p>For optimization, I used <a href="http://sebastianruder.com/optimizing-gradient-descent/index.html#rmsprop">RMSprop</a>. It is an enhancement of the classic Stochastic Gradient Descent with the improvement that it uses a different learning rate for every single parameter. This learning rate depends on the last gradients of that parameter. Parameters that recently had multiple large updates get a smaller learning rate to avoid oscillation around minima of the loss function. That brings us to our loss function:</p>
<h5>Perplexity - the WTF metric</h5>
<p>As a loss function I chose the cross-entropy loss based on the prediction the model made at each step / for each character. However, in the charts below I exponentiated each loss value with base 2. This makes the values easier to interpret, because: the cross-entropy \(H\) can be interpreted as the average number of bits that the model would need to encode the next letter at each step.
    <button class="show-more" data-target-id="perplexity-explanation" data-show-text="Why?" data-hide-text="OK, got it.">Why?</button>
</p>
<div id="perplexity-explanation" class="detail">
    <p>Say the model's task is to encode the text to bits and its aim is to minimize the number of bits it needs. For example, it might have recognized some likely characters, so it gives them a low number of bits. It encodes A to 01 and X to 00101. That is smart because A occurs way more often than X, so why spend an equal amount of bits on X as on A? So the better the model is at predicting the next character the less bits it will need to encode the text. This makes the cross-entropy a good error measure / loss function to optimize. See <a href="http://stats.stackexchange.com/questions/80967/qualitively-what-is-cross-entropy">this excellent answer on StackOverflow</a> for more info.</p>
    <p>Because our model learns patterns between characters in sentences it would not just look at the probability of each letter based on the number of occurrences in the text. Instead, it is smarter and uses the current position in the text for encoding and decoding. For example, if the whole text is a repetition of the pattern ABCDABCD, it wouldn't have to give each letter 2 bits based on its direct probability of 0.25. Instead, it would just have to encode the first letter, the rest of the text would be directly determined by that. So, it needs 2 bits <strong>for the whole text.</strong></p>
    <p>Anyhow, why exponentiate the cross-entropy? So remember that the cross-entropy \(H\) gives us the average number of bits the model would need to encode the next letter at each step.</p>
</div>
<p>Thus, \(2^{H}\) gives us the average number of possibilities it has to choose from. Say our input data consists of 1000 characters and the model achieves a cross-entropy of 3.322 bits per character. This would mean a perplexity of \(2^{3.322} = 10\). So, the model is as confused on the input data as if it had to choose uniformly and independently among 10 possibilities for each character (example taken from <a href="https://en.wikipedia.org/wiki/Perplexity">this Wiki article</a>).</p>
<h5>Initial Hyperparameters</h5>
<ul>
    <li>Number of LSTM layers: 2</li>
    <li>Number of neurons per layer: 512</li>
    <li>Batch size: 1</li>
    <li>Number of timesteps for each backpropagation: 40<br/>This means the data is given in chunks of 40 characters. For each character, the model looks compares its output with the correct output. Then it does backpropagation from the current step to the start of the chunk of characters to see whether it would have made a better prediction if it had behaved differently in an earlier step. Consequently, the network optimizes its parameters looking 1-40 timesteps into the past.</li>
    <li>Learning rate: 0.005</li>
    <li>Learning rate decay: 0.9</li>
    <li>Probability of keeping the output: 0.8<br/>This refers to the dropout technique, in which each LSTM cell either keeps its calculated output or outputs zero.</li>
</ul>
<p>Small details:</p>
<ul>
    <li>I <a href="http://www.wildml.com/deep-learning-glossary/#gradient-clipping">clipped the gradients</a> to an L2 norm of 5.</li>
    <li><p>The hidden state of the LSTM never gets reset during training. Even though each backpropagation run is only done within chunks of 40 characters, the model can use the last hidden state of the last chunk when predicting the first character of the current chunk. Thus, the hidden state is zero at the very start of training, but then only changes as a result of the LSTM's update rules.</p>
        <p>This behavior will change later, as it leads to suboptimal results.</p></li>
</ul>

<h3>1. Batch Size</h3>
<p>I thought it might be smart to start with the batch size, because it will influence, how fast and efficient the training will be in future experiments. For a batch size of \(n\), I split up the text into \(n\) parts and fed these parts simultaneously to the model. Thus, each LSTM layer had \(n\) different and independent hidden states, one for each part of the text. The network's parameters however were shared, used simultaneously for all batches and optimized on all of them - just like in regular mini-batch learning. Splitting up the text leads to minor distortions of the data, because each batch starts without any context and probably in the middle of a word or sentence, but I assume this has no noticeable effect on the loss.</p>
<p>Here you can see validation losses and the minutes per epoch for different batch sizes.</p>
<div class="col-xs-9 no-padding">
    <canvas id="batch-size-decay-chart" class="chart" width="600" height="300"></canvas>
</div>
<div class="col-xs-3 no-padding">
    <canvas id="batch-size-epoch-duration-chart" width="200" height="300"></canvas>
</div>
<p>Before interpreting the results, I should note that it is unfair to compare different batch sizes with the same learning rate. For larger batch sizes, the steps that the optimizer takes are more stable, because it optimizes / generalizes on multiple samples at once. Thus, we can use a higher learning rate with higher batch sizes meaning each batch size has a different optimal learning rate. This is to some extent compensated by the RMSProp optimizer, which adapts the learning rate over time.</p>
<p>As for the interpretation:</p>
<ul>
    <li>We can see that batch sizes of 1, 10 and 20 are definitely too inefficient. I also concluded that 1 and 10 overfit because they see too little sentences at the same time. This means that the parameters get optimized too much on the current sentence instead of on the whole text. This could be compensated by a lower learning rate though.</li>
    <li><p>We can also see that batch sizes of 500 and 2000 converge slower - both in terms of epochs and actual training time. I attribute this to the limited effect that increasing the batch size has on the stability of the gradient step. Calculating a gradient step on just one sample is much noisier than calculating it on 100 samples combined. But a gradient step calculated on 100,000 samples might not be much more stable than the step calculated on the 100 samples. The error function based on the 100 samples might already approximate the error function of the whole dataset quite well. Thus, calculating the gradient w.r.t. the 99,900 other samples is a waste of time, because it results in more or less the same gradient step.</p>
        <p>In the chart above, the x axis is the number of epochs. Say, the 2000-batch-size model does 100 steps per epoch while the 50-batch-size model does 4,000 steps per epoch. If we now assume that both models take gradient steps with more or less the same stability, it makes sense that models with a batch size < 2000 converge much faster, because they take more steps per epoch. The speed uplift of using a batch size of 2000 cannot compensate this disadvantage.</p>
        <p>For more info on the effect of batch sizes on the convergence, you can read <a href="https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent/answer/Brian-Wong-21">this excellent answer</a>.</p></li>
</ul>

<p>I chose 200 as a batch size, because it causes a low time per epoch and a fast convergence - when measuring the training time instead of epochs, batch sizes of 50, 100 and 200 led to roughly the same convergence.</p>

<div class="alert alert-info">
    <strong>Lesson Learned:</strong> Choose a good batch size first, because it affects the training time of future experiments.
</div>

<p>Throughout the training of all experiments, I let the models complete a sentence started with "The " every now and then. This was a good evaluation metric in addition to the validation loss. Here is the output of the model with a batch size of 200 after training:</p>

<blockquote>The house which had been the strange problem which had been the strange of the man who had been the strange of the man who had been the strange of the man who had been the strange of the man who had been the strange of the man who had been the stran...</blockquote>

<p>We can use this as a baseline to evaluate the impact of the following hyperparameter tuning.</p>

<h3>2. Learning Rate</h3>
<figure><canvas id="learning-rate-first-chart" class="chart" width="600" height="300"></canvas></figure>

<p>Carelessly, I went for 0.01 as the future learning rate, because of a marginally better validation loss. I regretted that choice later when I expanded the model to use more neurons per layer (section 5). Then, 0.01 was everything but the optimal learning rate. I should have read more about the RMSProp method before optimizing its parameters. (NÃ¤mlich) In the slides, where Geoffrey Hinton proposed RMSprop, he states that 0.001 is a good initial learning rate for most problems. </p>

<h3>All Experiments</h3>
<div class="col-xs-9">
    <canvas id="flexible-chart" class="chart" data-width="600" data-height="300"></canvas>
</div>
<div class="col-xs-3">
    <div class="chart-form-group">
        <div>
            <label for="run-group-select">Experiment</label>
            <div class="btn-group dropdown-full-width">
                <button id="run-group-select" type="button" value="batch_size" class="btn btn-default dropdown-toggle" onchange="plot(true)" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    <span class="choice">Batch Size</span> <span class="caret"></span>
                </button>
                <ul class="dropdown-menu">
                    <li><a href="#" data-value="batch_size">Batch Size</a></li>
                    <li><a href="#" data-value="learning_rate_512">Learning Rate</a></li>
                    <li><a href="#" data-value="learning_rate_decay">Learning Rate Decay</a></li>
                    <li><a href="#" data-value="num_timesteps">Number of Timesteps</a></li>
                    <li><a href="#" data-value="num_neurons_1024_failed_starts">1024 Neurons Failed Starts</a></li>
                    <li><a href="#" data-value="learning_rate_1024">Learning Rate (1024 Neurons)</a></li>
                    <li><a href="#" data-value="num_neurons">Neurons per Layer</a></li>
                    <li><a href="#" data-value="output_keep_prob">Output Keep Prob.</a></li>
                    <li><a href="#" data-value="num_layers">Number of Layers</a></li>
                    <li><a href="#" data-value="reset_state_interval_tokens">Reset State after Tokens</a></li>
                    <li role="separator" class="divider"></li>
                    <li><a href="#" data-value="wiki">Wikipedia</a></li>
                    <li><a href="#" data-value="south_park">South Park</a></li>
                    <li><a href="#" data-value="congress">Congress Transcripts</a></li>
                    <li><a href="#" data-value="goethe">Goethe Poems</a></li>
                </ul>
            </div>
        </div>
        <div>
            <label>X Axis</label>
            <div class="btn-group dropdown-full-width">
                <button id="x-axis-select" type="button" value="minutesSinceStart" class="btn btn-default dropdown-toggle" onchange="plot()" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    <span class="choice">Training Time</span> <span class="caret"></span>
                </button>
                <ul class="dropdown-menu">
                    <li><a href="#" data-value="minutesSinceStart">Training Time</a></li>
                    <li><a href="#" data-value="epochs">Epochs</a></li>
                </ul>
            </div>
        </div>
        <div>
            <label for="y-axis-select">Y Axis</label>
            <div class="btn-group dropdown-full-width">
                <button id="y-axis-select" type="button" value="lossesValid" class="btn btn-default dropdown-toggle" onchange="plot(true)" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    <span class="choice">Validation Loss</span> <span class="caret"></span>
                </button>
                <ul class="dropdown-menu">
                    <li><a href="#" data-value="lossesValid">Validation Loss</a></li>
                    <li><a href="#" data-value="lossesTrain">Training Loss</a></li>
                </ul>
            </div>
        </div>
        <div>
            <label for="y-axis-range">Y Axis Range</label>
            <input id="y-axis-range">
        </div>
        <div>
            <button id="export-button" type="button" class="btn btn-default" onclick="exportChart()">Export Chart</button>
        </div>
    </div>
</div>

<input id="stylesheets-input" value="stylesheets/posts/char-lm.css" style="display: none;">
<input id="javascripts-input" value="https://cdnjs.cloudflare.com/ajax/libs/he/1.1.1/he.min.js javascripts/posts/char-lm/text-complete.js javascripts/posts/char-lm/plot-flexible.js javascripts/posts/char-lm/plot.js" style="display: none;">